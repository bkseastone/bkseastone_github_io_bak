<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh" xml:lang="zh">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>机器学习:三个层次</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="style.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="icon" href="../../imgs/favicon.ico" type="image/x-icon"/> <link rel="shortcut icon" href="../../imgs/favicon.ico" type="image/x-icon" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-140731880-1"></script>
  <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date());
  gtag('config', 'UA-140731880-1'); </script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">机器学习:三个层次</h1>
<p class="date">2018-10-09 15:35:42</p>
</header>
<nav id="TOC">
<ul>
<li><a href="#机器学习三个层次">机器学习:三个层次</a><ul>
<li><a href="#极大似然估计">极大似然估计</a></li>
<li><a href="#贝叶斯估计最大后验估计">贝叶斯估计（最大后验估计）</a></li>
<li><a href="#贝叶斯推理">贝叶斯推理</a></li>
<li><a href="#总结">总结</a></li>
</ul></li>
</ul>
</nav>
<h1 id="机器学习三个层次">机器学习:三个层次</h1>
<h2 id="极大似然估计">极大似然估计</h2>
<h3 id="理解">理解</h3>
<p>用最大似然来学习数据中的模式时，当数据点数远小于参数数量时，会出现过拟合（因自由度远高于数据点数而导致的某些项被过度调参的情况，当出现这种情况时会导致模型的泛化能力急剧下降）的问题，所以不得不根据可得到的训练集的规模限制参数的数量。这种由表象得出的问题及其解决方案，很明显无法说明最大似然与过拟合的关联性，所以解决方案也显得非常不合逻辑（更为合理的解决方法似乎应是根据待解决问题的复杂性来限制参数的数量），下面以一个例子来说明最大似然与过拟合的内在联系：</p>
<p>假设要估计的 <span class="math inline">\(Y \sim N( \mu , \sigma^2)\)</span> ，暂且不考虑 y 与 x 的关系，当 <span class="math inline">\(\mu\)</span> 已知， <span class="math inline">\(\frac{1}{n} \sum (Y_i - \mu)^2\)</span> 是 <span class="math inline">\(\mu\)</span> 的一个无偏估计；</p>
<figure>
<img src="https://bkseastone.github.io/images/maxLikelyhood.jpg" alt="maxLikelyhood" /><figcaption>maxLikelyhood</figcaption>
</figure>
<p>而当用最大似然来做模式识别时， <span class="math inline">\(\mu\)</span> 是未知的，极大似然是用 <span class="math inline">\(\bar{Y}\)</span> 来估计 <span class="math inline">\(\mu\)</span> 的，此时拟合出的估计分布的方差自然为 <span class="math inline">\(\frac{1}{n} \sum (Y_i - \bar{Y})^2\)</span> ，对于无偏估计 <span class="math inline">\(\frac{1}{n} \sum (Y_i - \mu)^2\)</span> 来说，当且仅当 <span class="math inline">\(\mu = \frac{1}{n} \sum Y_i\)</span> 时取得最小值，故在数据量过少，而模型复杂度很高的情况下，用极大似然做拟合时（极大似然倾向于将拟合出的估计分布的方差做到最小），为使方差足够小，会导致 <span class="math inline">\(\bar{Y}\)</span> 与 <span class="math inline">\(\mu\)</span> 偏差过大，称之为过拟合，即<strong>过拟合的现象是 <span class="math inline">\(\bar{Y}\)</span> 与 <span class="math inline">\(\mu\)</span> 偏差过大，本质是参数自由度过高导致的方差过小</strong> 。</p>
<h3 id="计算">计算</h3>
<blockquote>
<p>对 <span class="math inline">\(p(t|x;w, \beta)\)</span> 建模，通过最大化<strong><em>样本的出现概率</em></strong>（直接拟合）求解模型参数，没有先后验一说。</p>
</blockquote>
<p>似然函数为： <span class="math display">\[
p(y|x;w, \beta) = \prod_i^N N(f(x_i,w), \frac{1}{\beta}) = \prod_i^N (\frac{\beta}{2 \pi})^{\frac{1}{2}} e^{- \frac{\beta}{2}(f(x_i,w)-y_i)^2}
\]</span> 对数似然为： <span class="math display">\[
\ln p(y|x;w, \beta) = - \frac{\beta}{2} \sum_i^N (f(x_i,w)-y_i)^2 + \frac{N}{2} (\ln \beta - \ln 2 \pi)
\]</span> 可在对数似然的极值处求得 <span class="math inline">\(w_{ML}\)</span> ，进而得到 <span class="math inline">\(\frac{1}{\beta_{ML}} = \frac{1}{N} \sum_i^N (f(x_i, w_{ML})-y_i)^2\)</span> 。</p>
<p>最终得到拟合的估计分布为 <span class="math inline">\(p(y|x;w_{ML}, \beta_{ML}) = N(f(x_i,w_{ML}), \frac{1}{\beta_{ML}})\)</span> 。</p>
<h2 id="贝叶斯估计最大后验估计">贝叶斯估计（最大后验估计）</h2>
<h3 id="计算-1">计算</h3>
<blockquote>
<p>对 <span class="math inline">\(p(t|x;w, \beta)\)</span> 建模，通过最大化<strong><em>参数的后验概率</em></strong>求解模型参数。</p>
</blockquote>
<p>由 <span class="math display">\[
p(w|x,y; \alpha , \beta) \propto p(y|x; w, \beta) p(w| \alpha),
\]</span> 设<a href="https://mp.weixin.qq.com/s?__biz=MzU0MDQ1NjAzNg==&amp;mid=2247483983&amp;idx=1&amp;sn=e635ed5e0888f993f58d2dc97741b154&amp;chksm=fb39a744cc4e2e522201c275e81809b41a8ed430d6555d427bf4814eb58298cca88d96645b6f&amp;mpshare=1&amp;scene=1&amp;srcid=0324torNoEEsSxuG4XaueHCL&amp;pass_ticket=D6%2FBCOtakZrnYpfi7nkflZ1pEU26KzldpngFS0M8RG%2BzJFClg9qwLPOWtnP2XS5e#rd">先验概率</a>为（其中 <span class="math inline">\(\alpha\)</span> 为超参数，为<strong>模型参数的先验方差的倒数</strong>） <span class="math display">\[
p(w| \alpha) = N(0, \alpha^{-1} I) = (\frac{\alpha}{2 \pi})^{\frac{M+1}{2}} e^{-\frac{\alpha}{2} w^T w},
\]</span> 故后验概率为 <span class="math display">\[
(\prod_i^N (\frac{\beta}{2 \pi})^{\frac{1}{2}} e^{-\frac{\beta}{2} (f(x_i, w) - y_i)^2}) (\frac{\alpha}{2 \pi})^{\frac{M+1}{2}} e^{- \frac{\alpha}{2} w^T w}
\]</span> 取对数得 <span class="math display">\[
\sum_i^N p(y_i|x_i; w, \beta) + \frac{M+1}{2} (\ln \alpha - \ln 2 \pi) - \frac{\alpha}{2} w^T w
\]</span></p>
<p>故最大化后验概率等价于最小化该函数 <span class="math display">\[
\sum_i^N (f(x_i; w) - y_i)^2 + \frac{\alpha}{2} w^T w.
\]</span> 故先验即为正则项。</p>
<h2 id="贝叶斯推理">贝叶斯推理</h2>
<p>MLE、MAP是选择相对最好的一个模型（point estimation）， 贝叶斯方法则是通过观测数据来估计后验分布(posterior distribution)，并通过后验分布做群体决策，所以后者的目标并不是在去选择某一个最好的模型，贝叶斯估计复杂度大，通常用MCMC等近似算法来近似，这样做模型的ensemble的优点是它可以reduce variance。</p>
<h2 id="总结">总结</h2>
<p>首先建立数据的参数模型<span class="math inline">\(p(D;w)\)</span>，通过带参模型计算各样本出现的概率，然后</p>
<ul>
<li>最大化所有样本出现的概率，求得模型参数。（MLE）<span class="math inline">\(\max_w p(D|w)\)</span></li>
<li>将在所有样本<span class="math inline">\(D\)</span>已知的条件下<strong>模型参数<span class="math inline">\(w\)</span>的概率</strong>称为模型的后验概率，最大化模型的后验概率，求得模型参数。（MAP）<span class="math inline">\(\max_w p(w|D) = \max_w p(D|w)p(w)\)</span></li>
<li>求出模型的后验概率分布<span class="math inline">\(p(w|D)\)</span>，用积分做群体决策<span class="math inline">\(\int p(y|x;w)p(w|D) \mathrm{d} w\)</span>。（贝叶斯推理）</li>
</ul>
<a style="color:black;font-size:1em;float:right;margin-right:30px;margin-bottom:40px;" href="../../index.html">[Return to the homepage]</a>
</body>
</html>
